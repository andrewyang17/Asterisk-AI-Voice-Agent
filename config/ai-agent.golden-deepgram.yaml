# Monolithic Deepgram Voice Agent configuration
# Copy to config/ai-agent.yaml to run Deepgram's voice agent end-to-end.
# Requires DEEPGRAM_API_KEY in .env and OPENAI_API_KEY for the agent's "think" stage.

default_provider: "deepgram"

# Transport modes
audio_transport: "audiosocket"   # audiosocket | externalmedia
downstream_mode: "file"          # file is more tolerant; set to stream when ready

audiosocket:
  host: "0.0.0.0"
  port: 8090
  format: "ulaw"

# Optional tuning
barge_in:
  enabled: false
  initial_protection_ms: 400    # Drop inbound during agent intro; 200–600 ms. Higher = less echo, more delay.
  min_ms: 400                   # Sustained speech required to trigger; 250–600 ms. Lower = more sensitive.
  energy_threshold: 1800        # RMS threshold for speech detection; 1000–3000. Raise on noisy lines.
  cooldown_ms: 1000             # Ignore retriggers for this period after one fires; 500–1500 ms.
  post_tts_end_protection_ms: 250  # Guard after TTS ends to avoid clipping callers; 250–500 ms.

# VAD: add a `vad:` block if you need utterance segmentation control; see docs/Configuration-Reference.md

providers:
  deepgram:
    enabled: true
    api_key: "${DEEPGRAM_API_KEY}"
    model: "nova-2-general"
    tts_model: "aura-asteria-en"
    greeting: "${DEEPGRAM_GREETING:-Hello, how can I help you today?}"
    instructions: "${DEEPGRAM_INSTRUCTIONS:-You are a concise voice assistant. Respond in under 20 words and answer immediately.}"
    input_encoding: "linear16"
    input_sample_rate_hz: 8000
    continuous_input: true
    # Output μ-law for telephony playback; engine converts to files or stream per mode
    output_encoding: "mulaw"
    output_sample_rate_hz: 8000

# Canonical LLM defaults (used by provider unless overridden)
llm:
  initial_greeting: "Hello, how can I help you today?"
  prompt: "You are a concise and helpful voice assistant. Keep replies under 20 words unless asked for detail."
  model: "gpt-4o"
